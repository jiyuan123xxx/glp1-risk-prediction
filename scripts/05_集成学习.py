#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
GLP-1ä¸´åºŠè¯•éªŒé£é™©é¢„æµ‹ - é›†æˆå­¦ä¹ å»ºæ¨¡æ¨¡å—ï¼ˆåŸºäºçœŸå®æ ‡ç­¾ï¼‰
ä¼˜åŒ–ç‰ˆæœ¬ï¼šä¿®æ­£SMOTEæ•°æ®æ³„éœ²é—®é¢˜ï¼Œå¢åŠ PR-AUCå’Œé˜ˆå€¼ä¼˜åŒ–

åŠŸèƒ½ï¼š
1. åŠ è½½åŸºäºçœŸå®è¯•éªŒç»“æœçš„æ ‡ç­¾æ•°æ®
2. äº¤å‰éªŒè¯è¯„ä¼°åŸºç¡€æ¨¡å‹ï¼ˆSMOTEå†…åµŒäºCVï¼‰
3. æ„å»ºåŠ æƒé›†æˆå’Œå †å é›†æˆ
4. è¶…å‚æ•°è°ƒä¼˜å’Œæ¨¡å‹è¯„ä¼°
5. å¯è§£é‡Šæ€§åˆ†æ

ä½œè€…ï¼šç³»ç»Ÿç®¡ç†å‘˜
åˆ›å»ºæ—¥æœŸï¼š2026-02-22
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import joblib
import warnings
import os
import sys
from datetime import datetime
import matplotlib

# è®¾ç½®ä¸­æ–‡å­—ä½“æ”¯æŒ
matplotlib.rcParams['font.sans-serif'] = ['SimHei', 'Microsoft YaHei', 'DejaVu Sans']
matplotlib.rcParams['axes.unicode_minus'] = False

from sklearn.model_selection import (
    train_test_split, StratifiedKFold, GridSearchCV, cross_val_score
)
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import (
    RandomForestClassifier, GradientBoostingClassifier, StackingClassifier
)
from xgboost import XGBClassifier
from sklearn.metrics import (
    roc_auc_score, accuracy_score, precision_score, recall_score, f1_score,
    confusion_matrix, classification_report, roc_curve, auc,
    average_precision_score, precision_recall_curve
)
from sklearn.utils import resample
from sklearn.pipeline import Pipeline
from imblearn.over_sampling import SMOTE
from imblearn.pipeline import make_pipeline as make_imb_pipeline

# å¯é€‰ï¼šSHAP åˆ†æ
try:
    import shap
    SHAP_AVAILABLE = True
except ImportError:
    SHAP_AVAILABLE = False
    print("âš ï¸ SHAP æœªå®‰è£…ï¼Œå°†è·³è¿‡å¯è§£é‡Šæ€§åˆ†æã€‚")

warnings.filterwarnings('ignore')

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

# ------------------------------ é…ç½®å‚æ•° ------------------------------
RANDOM_STATE = 42
TEST_SIZE = 0.2                # æµ‹è¯•é›†æ¯”ä¾‹
CV_FOLDS = 5                    # äº¤å‰éªŒè¯æŠ˜æ•°
N_BOOTSTRAP = 1000              # Bootstrap é‡æŠ½æ ·æ¬¡æ•°ï¼ˆç”¨äºç½®ä¿¡åŒºé—´ï¼‰
USE_TIME_SPLIT = True           # æ˜¯å¦æŒ‰å¹´ä»½åˆ’åˆ†
TIME_THRESHOLD = 2018           # ç”¨ 2018 å¹´åŠä»¥åä½œä¸ºæµ‹è¯•é›†
USE_SMOTE = True                # æ˜¯å¦ä½¿ç”¨SMOTEå¤„ç†ç±»åˆ«ä¸å¹³è¡¡

# ------------------------------ æ•°æ®åŠ è½½ä¸é¢„å¤„ç† ------------------------------
def load_features_with_label():
    """åŠ è½½å¸¦æ ‡ç­¾çš„ç‰¹å¾çŸ©é˜µï¼ˆä½¿ç”¨æ­£ç¡®çš„æ ‡ç­¾å®šä¹‰ï¼‰"""
    data_path = os.path.join(
        os.path.dirname(os.path.dirname(os.path.abspath(__file__))), 
        'data', 'processed', 'glp1_18clinical_features_with_labels_correct.csv'
    )
    
    if not os.path.exists(data_path):
        print("âŒ å¸¦æ ‡ç­¾çš„ç‰¹å¾æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè¯·å…ˆè¿è¡Œ04_æ ‡ç­¾å®šä¹‰_æ­£ç¡®æ–¹æ³•.py")
        return None, None, None, None
    
    df = pd.read_csv(data_path)
    
    # æ£€æŸ¥æ ‡ç­¾åˆ—æ˜¯å¦å­˜åœ¨
    if 'label' not in df.columns:
        raise ValueError("ç‰¹å¾æ–‡ä»¶ä¸­æœªæ‰¾åˆ° 'label' åˆ—ï¼Œè¯·å…ˆå®šä¹‰æ ‡ç­¾ã€‚")
    
    # æå–ç‰¹å¾å’Œæ ‡ç­¾
    feature_cols = [c for c in df.columns if c not in ['nct_id', 'label']]
    X = df[feature_cols].values
    y = df['label'].values
    
    print(f"åŠ è½½æ•°æ®: {len(X)} ä¸ªæ ·æœ¬, {len(feature_cols)} ä¸ªç‰¹å¾")
    print(f"é«˜é£é™©æ ·æœ¬æ¯”ä¾‹: {y.mean():.2%}")
    
    # æ£€æŸ¥ç±»åˆ«ä¸å¹³è¡¡æƒ…å†µ
    high_risk_count = y.sum()
    low_risk_count = len(y) - high_risk_count
    print(f"é«˜é£é™©æ ·æœ¬æ•°: {high_risk_count}")
    print(f"ä½é£é™©æ ·æœ¬æ•°: {low_risk_count}")
    print(f"ç±»åˆ«ä¸å¹³è¡¡æ¯”ä¾‹: {low_risk_count/high_risk_count:.1f}:1")
    
    return X, y, feature_cols, df

def split_data(X, y, df, use_time_split=True, time_threshold=2018):
    """
    åˆ’åˆ†è®­ç»ƒ/æµ‹è¯•é›†
    - å¦‚æœ use_time_split=Trueï¼Œåˆ™åŸºäº start_year åˆ’åˆ†
    - å¦åˆ™éšæœºåˆ†å±‚åˆ’åˆ†
    """
    if use_time_split:
        # ç¡®ä¿ df ä¸­åŒ…å« start_year åˆ—
        if 'start_year' not in df.columns:
            raise ValueError("æŒ‰æ—¶é—´åˆ’åˆ†éœ€è¦ start_year åˆ—ï¼Œè¯·æ£€æŸ¥æ•°æ®ã€‚")
        train_mask = df['start_year'] < time_threshold
        test_mask = df['start_year'] >= time_threshold
        X_train, X_test = X[train_mask], X[test_mask]
        y_train, y_test = y[train_mask], y[test_mask]
        print(f"æ—¶é—´åˆ’åˆ†ï¼šè®­ç»ƒé›† {train_mask.sum()} æ ·æœ¬ (å¹´ä»½ < {time_threshold})ï¼Œæµ‹è¯•é›† {test_mask.sum()} æ ·æœ¬")
    else:
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=TEST_SIZE, stratify=y, random_state=RANDOM_STATE
        )
        print(f"éšæœºåˆ†å±‚åˆ’åˆ†ï¼šè®­ç»ƒé›† {len(X_train)} æ ·æœ¬ï¼Œæµ‹è¯•é›† {len(X_test)} æ ·æœ¬")
    
    # æ£€æŸ¥è®­ç»ƒé›†å’Œæµ‹è¯•é›†çš„ç±»åˆ«åˆ†å¸ƒ
    print(f"è®­ç»ƒé›†é«˜é£é™©æ¯”ä¾‹: {y_train.mean():.4f}")
    print(f"æµ‹è¯•é›†é«˜é£é™©æ¯”ä¾‹: {y_test.mean():.4f}")
    
    return X_train, X_test, y_train, y_test

# ------------------------------ åŸºç¡€æ¨¡å‹å®šä¹‰ ------------------------------
def get_base_models():
    """è¿”å›åŸºç¡€æ¨¡å‹å­—å…¸ï¼ŒåŒ…å«ç®€å•æ¨¡å‹å’Œé›†æˆæ¨¡å‹"""
    models = {
        'Logistic Regression': LogisticRegression(
            class_weight='balanced', max_iter=1000, random_state=RANDOM_STATE
        ),
        'Random Forest': RandomForestClassifier(
            n_estimators=200, max_depth=8, min_samples_split=10,
            class_weight='balanced', random_state=RANDOM_STATE, n_jobs=-1
        ),
        'XGBoost': XGBClassifier(
            n_estimators=200, max_depth=5, learning_rate=0.05,
            scale_pos_weight=1.0, random_state=RANDOM_STATE, n_jobs=-1,
            eval_metric='logloss'
        ),
        'Gradient Boosting': GradientBoostingClassifier(
            n_estimators=200, max_depth=5, learning_rate=0.05,
            random_state=RANDOM_STATE
        )
    }
    return models

# ------------------------------ äº¤å‰éªŒè¯è¯„ä¼°ï¼ˆå¸¦SMOTEï¼‰----------------------
def evaluate_models_cv_with_smote(X_train, y_train, models, cv_folds=5):
    """å¯¹æ¯ä¸ªæ¨¡å‹è¿›è¡Œäº¤å‰éªŒè¯ï¼Œä½¿ç”¨SMOTEå†…åµŒäºpipelineï¼Œè¿”å› AUC å‡å€¼å’Œæ ‡å‡†å·®"""
    cv = StratifiedKFold(n_splits=cv_folds, shuffle=True, random_state=RANDOM_STATE)
    results = {}
    
    print("\nğŸ” äº¤å‰éªŒè¯è¯„ä¼°åŸºç¡€æ¨¡å‹ï¼ˆå†…åµŒSMOTEï¼‰...")
    for name, model in models.items():
        # åˆ›å»ºå¸¦SMOTEçš„pipelineï¼ˆä»…åœ¨è®­ç»ƒæŠ˜å†…è¿‡é‡‡æ ·ï¼‰
        pipeline = make_imb_pipeline(SMOTE(random_state=RANDOM_STATE), model)
        aucs = cross_val_score(pipeline, X_train, y_train, cv=cv, scoring='roc_auc', n_jobs=-1)
        results[name] = {
            'auc_mean': aucs.mean(),
            'auc_std': aucs.std(),
            'model': model  # ä¿å­˜åŸå§‹æ¨¡å‹ï¼Œåç»­éœ€è¦é‡æ–°è®­ç»ƒæ—¶å†ä½¿ç”¨pipeline
        }
        print(f"{name}: CV AUC = {aucs.mean():.4f} Â± {aucs.std():.4f}")
    
    return results

# ------------------------------ åŠ æƒé›†æˆï¼ˆåŸºäº CV AUCï¼‰-------------------
def create_weighted_ensemble(X_train, y_train, X_test, y_test, models_cv_results):
    """
    åŸºäºäº¤å‰éªŒè¯ AUC è®¡ç®—æƒé‡ï¼Œåœ¨è®­ç»ƒé›†ä¸Šé‡æ–°è®­ç»ƒæ¨¡å‹ï¼ˆåº”ç”¨SMOTEï¼‰ï¼Œè¿”å›æµ‹è¯•é›†ä¸Šçš„é›†æˆé¢„æµ‹
    """
    # æƒé‡å½’ä¸€åŒ–
    weights = {}
    total_auc = sum([res['auc_mean'] for res in models_cv_results.values()])
    for name, res in models_cv_results.items():
        weights[name] = res['auc_mean'] / total_auc
    
    print("\nâš–ï¸ åŠ æƒé›†æˆæƒé‡ï¼ˆåŸºäº CV AUCï¼‰:")
    for name, w in weights.items():
        print(f"  {name}: {w:.4f}")
    
    # åœ¨å…¨éƒ¨è®­ç»ƒæ•°æ®ä¸Šé‡æ–°è®­ç»ƒæ¯ä¸ªæ¨¡å‹ï¼ˆä½¿ç”¨SMOTEï¼‰
    trained_models = {}
    for name, model in models_cv_results.items():
        # åˆ›å»ºå¸¦SMOTEçš„pipelineå¹¶è®­ç»ƒ
        pipeline = make_imb_pipeline(SMOTE(random_state=RANDOM_STATE), model['model'])
        pipeline.fit(X_train, y_train)
        trained_models[name] = pipeline
    
    # è·å–æµ‹è¯•é›†æ¦‚ç‡
    probas = np.zeros((len(X_test), len(trained_models)))
    for i, (name, pipeline) in enumerate(trained_models.items()):
        probas[:, i] = pipeline.predict_proba(X_test)[:, 1]
    
    # åŠ æƒå¹³å‡
    weighted_proba = np.zeros(len(X_test))
    for i, (name, w) in enumerate(weights.items()):
        weighted_proba += probas[:, i] * w
    
    # è®¡ç®—æŒ‡æ ‡
    auc = roc_auc_score(y_test, weighted_proba)
    pred = (weighted_proba >= 0.5).astype(int)
    recall = recall_score(y_test, pred)
    precision = precision_score(y_test, pred)
    f1 = f1_score(y_test, pred)
    acc = accuracy_score(y_test, pred)
    pr_auc = average_precision_score(y_test, weighted_proba)
    
    return {
        'auc': auc,
        'pr_auc': pr_auc,
        'recall': recall,
        'precision': precision,
        'f1': f1,
        'accuracy': acc,
        'y_pred_proba': weighted_proba,
        'y_pred': pred,
        'weights': weights,
        'trained_models': trained_models
    }

# ------------------------------ å †å é›†æˆ ------------------------------
def create_stacking_ensemble(X_train, y_train, X_test, y_test):
    """
    åˆ›å»ºå †å é›†æˆæ¨¡å‹ï¼Œä½¿ç”¨æ‰€æœ‰åŸºç¡€æ¨¡å‹ä½œä¸ºç¬¬ä¸€å±‚ï¼Œé€»è¾‘å›å½’ä½œä¸ºå…ƒæ¨¡å‹
    """
    base_estimators = [
        ('lr', LogisticRegression(class_weight='balanced', max_iter=1000, random_state=RANDOM_STATE)),
        ('rf', RandomForestClassifier(n_estimators=200, max_depth=8, min_samples_split=10,
                                      class_weight='balanced', random_state=RANDOM_STATE, n_jobs=-1)),
        ('xgb', XGBClassifier(n_estimators=200, max_depth=5, learning_rate=0.05,
                              scale_pos_weight=1.0, random_state=RANDOM_STATE, n_jobs=-1)),
        ('gbm', GradientBoostingClassifier(n_estimators=200, max_depth=5, learning_rate=0.05,
                                           random_state=RANDOM_STATE))
    ]
    
    meta_learner = LogisticRegression(penalty='l1', solver='saga', class_weight='balanced',
                                      max_iter=1000, random_state=RANDOM_STATE)
    
    # æ³¨æ„ï¼šå †å å†…éƒ¨ä¼šè¿›è¡Œ5æŠ˜äº¤å‰éªŒè¯ç”Ÿæˆå…ƒç‰¹å¾ï¼Œæ­¤æ—¶ä¸èƒ½ä½¿ç”¨SMOTEï¼Œå› ä¸ºSMOTEä¼šå¯¼è‡´æ³„éœ²ã€‚
    # æˆ‘ä»¬å°†åœ¨è®­ç»ƒå †å ä¹‹å‰å¯¹æ•´ä¸ªè®­ç»ƒé›†åº”ç”¨SMOTEï¼Œè¿™æ˜¯å®‰å…¨çš„ï¼Œå› ä¸ºæµ‹è¯•é›†ç‹¬ç«‹ã€‚
    smote = SMOTE(random_state=RANDOM_STATE)
    X_train_res, y_train_res = smote.fit_resample(X_train, y_train)
    
    stacking = StackingClassifier(
        estimators=base_estimators,
        final_estimator=meta_learner,
        cv=5,                     # å†…éƒ¨ 5 æŠ˜äº¤å‰éªŒè¯ç”Ÿæˆå…ƒç‰¹å¾
        stack_method='predict_proba',
        n_jobs=-1
    )
    
    stacking.fit(X_train_res, y_train_res)
    
    # æµ‹è¯•é›†è¯„ä¼°ï¼ˆæ³¨æ„æµ‹è¯•é›†æ˜¯åŸå§‹åˆ†å¸ƒï¼Œæœªè¿‡é‡‡æ ·ï¼‰
    y_pred_proba = stacking.predict_proba(X_test)[:, 1]
    y_pred = stacking.predict(X_test)
    auc = roc_auc_score(y_test, y_pred_proba)
    recall = recall_score(y_test, y_pred)
    precision = precision_score(y_test, y_pred)
    f1 = f1_score(y_test, y_pred)
    acc = accuracy_score(y_test, y_pred)
    pr_auc = average_precision_score(y_test, y_pred_proba)
    
    print(f"\nğŸ—ï¸ å †å é›†æˆæµ‹è¯•é›† AUC = {auc:.4f}, PR-AUC = {pr_auc:.4f}, å¬å›ç‡ = {recall:.4f}")
    
    return {
        'model': stacking,
        'auc': auc,
        'pr_auc': pr_auc,
        'recall': recall,
        'precision': precision,
        'f1': f1,
        'accuracy': acc,
        'y_pred_proba': y_pred_proba,
        'y_pred': y_pred
    }

# ------------------------------ Bootstrap ç½®ä¿¡åŒºé—´ ----------------------
def bootstrap_metric(y_true, y_pred_proba, metric_func, n_bootstrap=1000, alpha=0.95):
    """è®¡ç®— AUC çš„ bootstrap ç½®ä¿¡åŒºé—´"""
    np.random.seed(RANDOM_STATE)
    n = len(y_true)
    indices = np.arange(n)
    scores = []
    for _ in range(n_bootstrap):
        idx = resample(indices, replace=True)
        if len(np.unique(y_true[idx])) < 2:
            continue
        score = metric_func(y_true[idx], y_pred_proba[idx])
        scores.append(score)
    lower = np.percentile(scores, (1 - alpha) / 2 * 100)
    upper = np.percentile(scores, (1 + alpha) / 2 * 100)
    return lower, upper

# ------------------------------ å¯è§£é‡Šæ€§åˆ†æ ----------------------------
def explain_model(model, X_train, X_test, feature_names, model_type='tree'):
    """
    ç”Ÿæˆç‰¹å¾é‡è¦æ€§å›¾ï¼ˆæ ‘æ¨¡å‹ï¼‰å’Œ SHAP æ€»ç»“å›¾
    æ”¯æŒæ ‘æ¨¡å‹å’Œçº¿æ€§æ¨¡å‹
    """
    visualizations_dir = os.path.join(os.path.dirname(os.path.dirname(os.path.abspath(__file__))), 'results', 'visualizations')
    os.makedirs(visualizations_dir, exist_ok=True)
    
    # æ ‘æ¨¡å‹çš„ç‰¹å¾é‡è¦æ€§å›¾ï¼ˆä»…å½“æœ‰ feature_importances_ å±æ€§æ—¶ï¼‰
    if model_type == 'tree' and hasattr(model, 'feature_importances_'):
        importances = model.feature_importances_
        indices = np.argsort(importances)[::-1]
        
        plt.figure(figsize=(12, 8))
        plt.title("ç‰¹å¾é‡è¦æ€§åˆ†æï¼ˆæ ‘æ¨¡å‹ï¼‰", fontsize=16, fontweight='bold')
        plt.barh(range(len(indices)), importances[indices], align='center', color='skyblue')
        plt.yticks(range(len(indices)), [feature_names[i] for i in indices], fontsize=10)
        plt.xlabel("é‡è¦æ€§", fontsize=12)
        plt.gca().invert_yaxis()
        plt.tight_layout()
        plt.savefig(os.path.join(visualizations_dir, 'feature_importances_ensemble.png'), dpi=300, bbox_inches='tight')
        plt.close()
        
        print("âœ… ç‰¹å¾é‡è¦æ€§å›¾å·²ä¿å­˜")
    
    # SHAP åˆ†æï¼ˆæ”¯æŒæ ‘æ¨¡å‹å’Œçº¿æ€§æ¨¡å‹ï¼‰
    if SHAP_AVAILABLE:
        try:
            # æ ¹æ®æ¨¡å‹ç±»å‹é€‰æ‹©è§£é‡Šå™¨
            if model_type == 'tree':
                explainer = shap.TreeExplainer(model)
                shap_values = explainer.shap_values(X_test)
                if isinstance(shap_values, list):
                    shap_values = shap_values[1]  # äºŒåˆ†ç±»å–æ­£ç±»
            elif hasattr(model, 'coef_'):  # çº¿æ€§æ¨¡å‹ï¼ˆé€»è¾‘å›å½’ç­‰ï¼‰
                # æ³¨æ„ï¼šLinearExplaineréœ€è¦è®­ç»ƒæ•°æ®ä½œä¸ºèƒŒæ™¯
                explainer = shap.LinearExplainer(model, X_train)
                shap_values = explainer.shap_values(X_test)
            else:
                print("âš ï¸ æœªçŸ¥æ¨¡å‹ç±»å‹ï¼Œæ— æ³•è¿›è¡ŒSHAPåˆ†æ")
                return

            # ç”ŸæˆSHAPæ€»ç»“å›¾
            plt.figure(figsize=(10, 8))
            shap.summary_plot(shap_values, X_test, feature_names=feature_names, show=False)
            plt.title("SHAP ç‰¹å¾é‡è¦æ€§æ€»ç»“", fontsize=16, fontweight='bold')
            plt.tight_layout()
            plt.savefig(os.path.join(visualizations_dir, 'shap_summary_ensemble.png'), dpi=300, bbox_inches='tight')
            plt.close()
            print("âœ… SHAP æ€»ç»“å›¾å·²ä¿å­˜")
                
        except Exception as e:
            print(f"SHAP åˆ†æå¤±è´¥: {e}")
    else:
        print("âš ï¸ SHAP æœªå®‰è£…ï¼Œè·³è¿‡åˆ†æ")

# ------------------------------ é˜ˆå€¼ä¼˜åŒ– ----------------------------
def threshold_optimization(y_test, y_pred_proba, model_name):
    """ç»˜åˆ¶ç²¾ç¡®ç‡-å¬å›ç‡éšé˜ˆå€¼å˜åŒ–æ›²çº¿ï¼Œå¹¶è¾“å‡ºæœ€ä¼˜é˜ˆå€¼ï¼ˆæ ¹æ®F1ï¼‰"""
    precisions, recalls, thresholds = precision_recall_curve(y_test, y_pred_proba)
    # è®¡ç®—æ¯ä¸ªé˜ˆå€¼ä¸‹çš„F1åˆ†æ•°ï¼ˆé˜ˆå€¼å¯¹åº”precisionså’Œrecallsçš„é•¿åº¦æ¯”thresholdså¤š1ï¼Œéœ€å¯¹é½ï¼‰
    # é€šå¸¸thresholdsçš„é•¿åº¦ç­‰äºprecisions-1ï¼Œæˆ‘ä»¬å¯ä»¥å–precisionså’Œrecallsçš„å‰len(thresholds)ä¸ª
    f1_scores = 2 * (precisions[:-1] * recalls[:-1]) / (precisions[:-1] + recalls[:-1] + 1e-10)
    best_idx = np.argmax(f1_scores)
    best_threshold = thresholds[best_idx]
    best_f1 = f1_scores[best_idx]
    
    plt.figure(figsize=(10, 6))
    plt.plot(thresholds, precisions[:-1], label='ç²¾ç¡®ç‡', linewidth=2)
    plt.plot(thresholds, recalls[:-1], label='å¬å›ç‡', linewidth=2)
    plt.plot(thresholds, f1_scores, label='F1åˆ†æ•°', linestyle='--', linewidth=2)
    plt.axvline(x=best_threshold, color='red', linestyle=':', label=f'æœ€ä¼˜é˜ˆå€¼ = {best_threshold:.2f}')
    plt.xlabel('é˜ˆå€¼')
    plt.ylabel('åˆ†æ•°')
    plt.title(f'{model_name} - ç²¾ç¡®ç‡/å¬å›ç‡éšé˜ˆå€¼å˜åŒ–')
    plt.legend()
    plt.grid(True, alpha=0.3)
    visualizations_dir = os.path.join(os.path.dirname(os.path.dirname(os.path.abspath(__file__))), 'results', 'visualizations')
    os.makedirs(visualizations_dir, exist_ok=True)
    plt.savefig(os.path.join(visualizations_dir, f'threshold_{model_name.replace(" ", "_")}.png'), dpi=300, bbox_inches='tight')
    plt.close()
    
    print(f"  æœ€ä¼˜é˜ˆå€¼: {best_threshold:.4f}, å¯¹åº”F1: {best_f1:.4f}")
    return best_threshold, best_f1

# ------------------------------ ä¸»æµç¨‹ ------------------------------
def main():
    print("=" * 60)
    print("GLP-1 ä¸´åºŠè¯•éªŒé£é™©é¢„æµ‹ï¼šé›†æˆå­¦ä¹ å»ºæ¨¡ï¼ˆåŸºäºçœŸå®æ ‡ç­¾ï¼‰")
    print("=" * 60)
    
    # 1. åŠ è½½æ•°æ®
    X, y, feature_names, df = load_features_with_label()
    if X is None:
        return
    
    # 2. åˆ’åˆ†è®­ç»ƒ/æµ‹è¯•é›†
    X_train, X_test, y_train, y_test = split_data(
        X, y, df, use_time_split=USE_TIME_SPLIT, time_threshold=TIME_THRESHOLD
    )
    
    # 3. æ ‡å‡†åŒ–ï¼ˆä»…æ‹Ÿåˆè®­ç»ƒé›†ï¼‰
    scaler = StandardScaler()
    X_train_scaled = scaler.fit_transform(X_train)
    X_test_scaled = scaler.transform(X_test)
    
    # 4. å®šä¹‰åŸºç¡€æ¨¡å‹
    base_models = get_base_models()
    
    # 5. äº¤å‰éªŒè¯è¯„ä¼°åŸºç¡€æ¨¡å‹ï¼ˆå†…åµŒSMOTEï¼‰
    cv_results = evaluate_models_cv_with_smote(X_train_scaled, y_train, base_models, CV_FOLDS)
    
    # 6. åŠ æƒé›†æˆï¼ˆåŸºäº CV AUCï¼‰
    print("\nğŸ”— æ„å»ºåŠ æƒé›†æˆæ¨¡å‹...")
    weighted_result = create_weighted_ensemble(
        X_train_scaled, y_train, X_test_scaled, y_test, cv_results
    )
    
    # 7. å †å é›†æˆ
    print("\nğŸ—ï¸ æ„å»ºå †å é›†æˆæ¨¡å‹...")
    stacking_result = create_stacking_ensemble(X_train_scaled, y_train, X_test_scaled, y_test)
    
    # 8. æµ‹è¯•é›†ä¸Šè¯„ä¼°æ‰€æœ‰æ¨¡å‹å¹¶æ¯”è¾ƒ
    print("\nğŸ“Š æµ‹è¯•é›†æ€§èƒ½æ¯”è¾ƒï¼ˆå¸¦ 95% CIï¼‰:")
    results = {}
    
    # åŸºç¡€æ¨¡å‹åœ¨æµ‹è¯•é›†ä¸Šçš„æ€§èƒ½ï¼ˆè®­ç»ƒæ—¶åº”ç”¨SMOTEï¼‰
    for name, model in base_models.items():
        # ä½¿ç”¨SMOTEé‡æ–°è®­ç»ƒ
        pipeline = make_imb_pipeline(SMOTE(random_state=RANDOM_STATE), model)
        pipeline.fit(X_train_scaled, y_train)
        y_pred_proba = pipeline.predict_proba(X_test_scaled)[:, 1]
        y_pred = pipeline.predict(X_test_scaled)
        auc = roc_auc_score(y_test, y_pred_proba)
        pr_auc = average_precision_score(y_test, y_pred_proba)
        recall = recall_score(y_test, y_pred)
        precision = precision_score(y_test, y_pred)
        f1 = f1_score(y_test, y_pred)
        acc = accuracy_score(y_test, y_pred)
        lower, upper = bootstrap_metric(y_test, y_pred_proba, roc_auc_score, N_BOOTSTRAP)
        results[name] = {
            'auc': auc, 'auc_ci': (lower, upper), 'pr_auc': pr_auc,
            'recall': recall, 'precision': precision, 'f1': f1, 'accuracy': acc
        }
        print(f"{name:20s} AUC = {auc:.4f} (95% CI [{lower:.4f}, {upper:.4f}]), PR-AUC = {pr_auc:.4f}, Recall = {recall:.4f}")
    
    # åŠ æƒé›†æˆ
    results['Weighted Ensemble'] = {
        'auc': weighted_result['auc'],
        'pr_auc': weighted_result['pr_auc'],
        'recall': weighted_result['recall'],
        'precision': weighted_result['precision'],
        'f1': weighted_result['f1'],
        'accuracy': weighted_result['accuracy']
    }
    lower, upper = bootstrap_metric(y_test, weighted_result['y_pred_proba'], roc_auc_score, N_BOOTSTRAP)
    print(f"{'Weighted Ensemble':20s} AUC = {weighted_result['auc']:.4f} (95% CI [{lower:.4f}, {upper:.4f}]), PR-AUC = {weighted_result['pr_auc']:.4f}, Recall = {weighted_result['recall']:.4f}")
    
    # å †å é›†æˆ
    results['Stacking'] = {
        'auc': stacking_result['auc'],
        'pr_auc': stacking_result['pr_auc'],
        'recall': stacking_result['recall'],
        'precision': stacking_result['precision'],
        'f1': stacking_result['f1'],
        'accuracy': stacking_result['accuracy']
    }
    lower, upper = bootstrap_metric(y_test, stacking_result['y_pred_proba'], roc_auc_score, N_BOOTSTRAP)
    print(f"{'Stacking':20s} AUC = {stacking_result['auc']:.4f} (95% CI [{lower:.4f}, {upper:.4f}]), PR-AUC = {stacking_result['pr_auc']:.4f}, Recall = {stacking_result['recall']:.4f}")
    
    # 9. é˜ˆå€¼ä¼˜åŒ–ï¼ˆå¯¹æœ€ä½³æ¨¡å‹ï¼‰
    best_model_name = max(results, key=lambda x: results[x]['auc'])
    best_result = results[best_model_name]
    print(f"\nğŸ† æœ€ä½³æ¨¡å‹: {best_model_name}, æµ‹è¯•é›† AUC = {best_result['auc']:.4f}, PR-AUC = {best_result['pr_auc']:.4f}")
    
    # è·å–æœ€ä½³æ¨¡å‹çš„é¢„æµ‹æ¦‚ç‡
    if best_model_name == 'Stacking':
        best_proba = stacking_result['y_pred_proba']
    elif best_model_name == 'Weighted Ensemble':
        best_proba = weighted_result['y_pred_proba']
    else:
        # åŸºç¡€æ¨¡å‹
        pipeline = make_imb_pipeline(SMOTE(random_state=RANDOM_STATE), base_models[best_model_name])
        pipeline.fit(X_train_scaled, y_train)
        best_proba = pipeline.predict_proba(X_test_scaled)[:, 1]
    
    print("\nğŸ”§ é˜ˆå€¼ä¼˜åŒ–...")
    best_thresh, best_f1 = threshold_optimization(y_test, best_proba, best_model_name)
    
    # åº”ç”¨æœ€ä¼˜é˜ˆå€¼é‡æ–°è®¡ç®—æ··æ·†çŸ©é˜µ
    y_pred_opt = (best_proba >= best_thresh).astype(int)
    cm_opt = confusion_matrix(y_test, y_pred_opt)
    print(f"ä¼˜åŒ–åæ··æ·†çŸ©é˜µï¼ˆé˜ˆå€¼={best_thresh:.4f}ï¼‰:")
    print(cm_opt)
    
    # 10. ä¿å­˜æœ€ä½³æ¨¡å‹å’Œ scaler
    models_dir = os.path.join(os.path.dirname(os.path.dirname(os.path.abspath(__file__))), 'models')
    os.makedirs(models_dir, exist_ok=True)
    
    joblib.dump(scaler, os.path.join(models_dir, 'scaler.pkl'))
    
    if best_model_name == 'Stacking':
        final_model = stacking_result['model']
        joblib.dump(final_model, os.path.join(models_dir, 'best_model.pkl'))
    elif best_model_name == 'Weighted Ensemble':
        # åŠ æƒé›†æˆä¸æ˜¯ä¸€ä¸ªå•ä¸€çš„ scikit-learn æ¨¡å‹ï¼Œæˆ‘ä»¬ä¿å­˜å…¶ç»„ä»¶
        final_model = weighted_result['trained_models']  # å­—å…¸
        joblib.dump(final_model, os.path.join(models_dir, 'weighted_ensemble_models.pkl'))
    else:
        # ä¿å­˜åŸºç¡€æ¨¡å‹çš„pipelineï¼ˆåŒ…å«SMOTEï¼‰
        final_pipeline = make_imb_pipeline(SMOTE(random_state=RANDOM_STATE), base_models[best_model_name])
        final_pipeline.fit(X_train_scaled, y_train)
        joblib.dump(final_pipeline, os.path.join(models_dir, 'best_model_pipeline.pkl'))
    
    # ä¿å­˜ç‰¹å¾åç§°
    pd.Series(feature_names).to_csv(os.path.join(models_dir, 'feature_names.csv'), index=False)
    print("âœ… æ¨¡å‹åŠé™„å±æ–‡ä»¶å·²ä¿å­˜è‡³ models/ ç›®å½•")
    
    # 11. å¯è§£é‡Šæ€§åˆ†æï¼ˆå¯¹æœ€ä½³æ¨¡å‹ï¼‰
    print("\nğŸ” å¼€å§‹å¯è§£é‡Šæ€§åˆ†æ...")
    if best_model_name in base_models:
        # é‡æ–°è®­ç»ƒä¸€ä¸ªæ— SMOTEçš„æ¨¡å‹ç”¨äºè§£é‡Šï¼ˆå› ä¸ºSMOTEä¼šæ”¹å˜æ•°æ®åˆ†å¸ƒï¼Œä½†ç‰¹å¾é‡è¦æ€§é€šå¸¸ä¸å˜ï¼‰
        explain_model(base_models[best_model_name], X_train_scaled, X_test_scaled, feature_names,
                      model_type='tree' if 'Forest' in best_model_name or 'XGB' in best_model_name or 'Gradient' in best_model_name else 'linear')
    elif best_model_name == 'Stacking':
        print("å †å æ¨¡å‹å¯è§£é‡Šæ€§ï¼šå±•ç¤ºéšæœºæ£®æ—åŸºæ¨¡å‹çš„ç‰¹å¾é‡è¦æ€§")
        rf_model = stacking_result['model'].named_estimators_['rf']
        explain_model(rf_model, X_train_scaled, X_test_scaled, feature_names, model_type='tree')
    elif best_model_name == 'Weighted Ensemble':
        max_weight_model_name = max(weighted_result['weights'], key=weighted_result['weights'].get)
        print(f"åŠ æƒé›†æˆä¸­æƒé‡æœ€é«˜çš„æ¨¡å‹: {max_weight_model_name}")
        # è·å–è¯¥æ¨¡å‹çš„åŸå§‹æœªåŒ…è£…æ¨¡å‹ï¼ˆä¸æ˜¯pipelineï¼‰
        model_to_explain = base_models[max_weight_model_name]
        explain_model(model_to_explain, X_train_scaled, X_test_scaled, feature_names,
                      model_type='tree' if 'Forest' in max_weight_model_name or 'XGB' in max_weight_model_name or 'Gradient' in max_weight_model_name else 'linear')
    
    # 12. ç”Ÿæˆæ€§èƒ½æ¯”è¾ƒå›¾è¡¨
    print("\nğŸ“ˆ ç”Ÿæˆæ€§èƒ½æ¯”è¾ƒå›¾è¡¨...")
    model_names = list(results.keys())
    auc_values = [results[name]['auc'] for name in model_names]
    recall_values = [results[name]['recall'] for name in model_names]
    pr_auc_values = [results[name]['pr_auc'] for name in model_names]
    
    fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(18, 6))
    
    # AUC æ¯”è¾ƒ
    bars1 = ax1.bar(model_names, auc_values, color=['skyblue', 'lightgreen', 'orange', 'pink', 'lightcoral', 'gold'])
    ax1.set_title('æ¨¡å‹AUCæ€§èƒ½æ¯”è¾ƒ', fontsize=14, fontweight='bold')
    ax1.set_ylabel('AUC')
    ax1.set_ylim(0, 1)
    ax1.tick_params(axis='x', rotation=45)
    for bar, auc_val in zip(bars1, auc_values):
        ax1.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01, 
                f'{auc_val:.3f}', ha='center', va='bottom', fontweight='bold')
    
    # å¬å›ç‡æ¯”è¾ƒ
    bars2 = ax2.bar(model_names, recall_values, color=['skyblue', 'lightgreen', 'orange', 'pink', 'lightcoral', 'gold'])
    ax2.set_title('æ¨¡å‹å¬å›ç‡æ¯”è¾ƒ', fontsize=14, fontweight='bold')
    ax2.set_ylabel('å¬å›ç‡')
    ax2.set_ylim(0, 1)
    ax2.tick_params(axis='x', rotation=45)
    for bar, recall_val in zip(bars2, recall_values):
        ax2.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01, 
                f'{recall_val:.3f}', ha='center', va='bottom', fontweight='bold')
    
    # PR-AUCæ¯”è¾ƒ
    bars3 = ax3.bar(model_names, pr_auc_values, color=['skyblue', 'lightgreen', 'orange', 'pink', 'lightcoral', 'gold'])
    ax3.set_title('æ¨¡å‹PR-AUCæ¯”è¾ƒ', fontsize=14, fontweight='bold')
    ax3.set_ylabel('PR-AUC')
    ax3.set_ylim(0, 1)
    ax3.tick_params(axis='x', rotation=45)
    for bar, pr_auc_val in zip(bars3, pr_auc_values):
        ax3.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01, 
                f'{pr_auc_val:.3f}', ha='center', va='bottom', fontweight='bold')
    
    plt.tight_layout()
    visualizations_dir = os.path.join(os.path.dirname(os.path.dirname(os.path.abspath(__file__))), 'results', 'visualizations')
    os.makedirs(visualizations_dir, exist_ok=True)
    plt.savefig(os.path.join(visualizations_dir, 'model_performance_comparison.png'), dpi=300, bbox_inches='tight')
    plt.close()
    
    print("âœ… æ€§èƒ½æ¯”è¾ƒå›¾è¡¨å·²ä¿å­˜")
    
    # 13. ä¿å­˜æ€§èƒ½ç»“æœ
    performance_df = pd.DataFrame(results).T
    reports_dir = os.path.join(os.path.dirname(os.path.dirname(os.path.abspath(__file__))), 'results', 'reports')
    os.makedirs(reports_dir, exist_ok=True)
    performance_df.to_csv(os.path.join(reports_dir, 'model_performance_results.csv'), encoding='utf-8')
    print("âœ… æ€§èƒ½ç»“æœå·²ä¿å­˜")
    
    # 14. ROCæ›²çº¿ç»˜åˆ¶ï¼ˆæœ€ä½³æ¨¡å‹ï¼‰
    plt.figure(figsize=(10, 8))
    fpr, tpr, _ = roc_curve(y_test, y_pred_proba_best)
    roc_auc = auc(fpr, tpr)
    plt.plot(fpr, tpr, lw=2, label=f'{best_model_name} (AUC = {roc_auc:.3f})')
    plt.plot([0, 1], [0, 1], 'k--', label='éšæœºåˆ†ç±»å™¨')
    plt.xlabel('å‡æ­£ç‡ (FPR)')
    plt.ylabel('çœŸæ­£ç‡ (TPR)')
    plt.title(f'ROCæ›²çº¿ - {best_model_name}')
    plt.legend()
    plt.grid(True, alpha=0.3)
    plt.savefig(os.path.join(visualizations_dir, 'roc_curve_ensemble.png'), dpi=300, bbox_inches='tight')
    plt.close()
    
    print("\nğŸ‰ é›†æˆå­¦ä¹ å»ºæ¨¡å®Œæˆï¼")
    print(f"æœ€ä½³æ¨¡å‹: {best_model_name}")
    print(f"æœ€ä½³AUC: {best_result['auc']:.4f}")
    print(f"æœ€ä½³PR-AUC: {best_result['pr_auc']:.4f}")
    print(f"æœ€ä½³å¬å›ç‡: {best_result['recall']:.4f}")
    print(f"ä¼˜åŒ–åé˜ˆå€¼: {best_thresh:.4f}, å¯¹åº”F1: {best_f1:.4f}")
    
    # 15. å¤‡é€‰æ–¹æ¡ˆï¼šå¼ºåˆ¶ä½¿ç”¨æ ‘æ¨¡å‹è¿›è¡Œ SHAP åˆ†æï¼ˆå³ä½¿æœ€ä½³æ¨¡å‹æ˜¯çº¿æ€§æ¨¡å‹ï¼‰
    if best_model_name != 'Random Forest':
        print("\nğŸ” é¢å¤–ä½¿ç”¨éšæœºæ£®æ—è¿›è¡Œ SHAP åˆ†æ...")
        rf_for_shap = RandomForestClassifier(
            n_estimators=200, max_depth=8, 
            class_weight='balanced', random_state=RANDOM_STATE
        )
        rf_for_shap.fit(X_train_scaled, y_train)
        explain_model(rf_for_shap, X_train_scaled, X_test_scaled, feature_names, model_type='tree')

if __name__ == "__main__":
    try:
        start_time = datetime.now()
        print(f"å¼€å§‹æ—¶é—´: {start_time.strftime('%Y-%m-%d %H:%M:%S')}")
        
        main()
        
        end_time = datetime.now()
        duration = (end_time - start_time).total_seconds()
        print(f"å®Œæˆæ—¶é—´: {end_time.strftime('%Y-%m-%d %H:%M:%S')}")
        print(f"å¤„ç†è€—æ—¶: {duration:.2f} ç§’")
        
    except Exception as e:
        print(f"âŒ é›†æˆå­¦ä¹ å»ºæ¨¡å¤±è´¥: {str(e)}")
        import traceback
        traceback.print_exc()
        sys.exit(1)